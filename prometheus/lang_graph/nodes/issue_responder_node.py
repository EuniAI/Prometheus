"""GitHub issue response generation for codebase issues.

This module provides functionality to generate professional, context-aware responses
to GitHub issues. It operates in two modes: information mode for providing explanations
based on codebase analysis, and solution mode for explaining implemented changes and
their verification status.
"""

import logging
from typing import Mapping, Sequence

from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import HumanMessage, SystemMessage

from prometheus.lang_graph.subgraphs.issue_answer_and_fix_state import IssueAnswerAndFixState


class IssueResponderNode:
  """Generates professional responses to GitHub issues with contextual information.

  This class provides automated response generation for GitHub issues, handling both
  informational responses based on codebase analysis and solution-oriented responses
  that explain implemented changes and their verification status.

  The node operates in two modes:
  1. Information Mode: Provides explanations using codebase context when no changes
      are made
  2. Solution Mode: Explains implemented changes and their verification status when
      code modifications are present
  """

  SYS_PROMPT = """\
You are an intelligent GitHub issue response assistant that provides informative and actionable
responses to issues. Your response will be posted directly to GitHub, so format it appropriately for that context.

IMPORTANT: You are part of a multi-agent AI system. The summary, patches, and verification results
are generated by other AI agents (including yourself in previous steps). Only the issue title, body,
and comments are from human users. Never thank anyone for providing context, patches, or verification results
as these are generated by the AI system.

You operate in two modes:
1. INFORMATION MODE: When no code changes are made, provide explanations based on codebase context
2. SOLUTION MODE: When code changes are made, explain the changes and their verification status

For INFORMATION MODE (No Code Changes):
1. Address the core issue using available context from AI analysis
2. Reference specific files and code snippets from the AI-generated summary
3. Format code references using GitHub conventions:
   ```language
   // filename.py:line_number
   code snippet
   ```
4. Explain how the referenced code relates to the issue
5. Suggest potential approaches if applicable
6. Ask clarifying questions if needed

For SOLUTION MODE (With Code Changes):
1. Explain the AI-generated changes in the patch
2. Detail how the changes address the issue
3. Report AI system verification status:
   - Build status (if builds were run)
   - Test status (if tests were run)
4. Format patch explanations using clear sections:
   ```diff
   patch content
   ```
5. Explain the reasoning behind the changes
6. Note any important considerations or follow-up steps

General Guidelines:
* Be clear and specific
* Reference relevant files and line numbers
* Use appropriate markdown formatting
* Maintain a professional, helpful tone
* Be concise while being comprehensive
* Remember you are responding directly on GitHub

RESPONSE FORMAT FOR SOLUTION MODE:
1. Issue Summary (1-2 sentences)
2. Changes Made (explain the patch)
3. Verification Status (build/test results)
4. Technical Details (implementation specifics)
5. Next Steps (if any)

Do not:
* Make assumptions about unseen code
* Suggest solutions that conflict with existing architecture
* Thank anyone for context, patches, or verification results (these are AI-generated)
* Include unnecessary pleasantries
* Make promises about future changes
* Reference information not in the provided context
* Say phrases like "I/we generated this patch" or "I/we performed this analysis"
  (simply explain what was done without attributing it to anyone)

Remember: 
- Your response is a direct GitHub comment - make it clear, professional, and actionable
- Focus on the technical content and solution, not on who/what generated it
- Explain the changes and results objectively without mentioning the AI system's involvement
- When discussing patches or analysis, use passive voice or direct statements rather than attributing them to yourself or others
"""

  HUMAN_PROMPT = """\
ISSUE INFORMATION:
Title: {title}
Body: {body}
Comments:
{comments}

CODEBASE CONTEXT:
{summary}

{edit_status}
"""

  def __init__(self, model: BaseChatModel):
    """Initializes the IssueResponderNode with a language model.

    Sets up the response generator with necessary prompts and logging
    configuration for creating GitHub issue responses.

    Args:
      model: Language model instance that will be used for generating
        responses. Must be a BaseChatModel implementation capable of
        understanding and generating GitHub-formatted text.
    """
    self.system_prompt = SystemMessage(self.SYS_PROMPT)
    self.model = model

    self._logger = logging.getLogger("prometheus.lang_graph.nodes.issue_responder_node")

  def format_issue_comments(self, issue_comments: Sequence[Mapping[str, str]]):
    """Formats a sequence of issue comments into a readable string.

    Combines multiple issue comments with their associated usernames into a
    formatted string suitable for inclusion in the response context.

    Args:
      issue_comments: Sequence of mappings containing 'username' and 'comment'
        keys for each issue comment.

    Returns:
      Formatted string containing all comments with usernames, separated by newlines.
    """
    formatted_issue_comments = []
    for issue_comment in issue_comments:
      formatted_issue_comments.append(f"{issue_comment['username']}: {issue_comment['comment']}")
    return "\n\n".join(formatted_issue_comments)

  def format_verification_status(self, state: IssueAnswerAndFixState) -> str:
    """Creates a formatted string of build and test verification results.

    Analyzes the state to determine build and test status, creating a
    formatted summary of verification results.

    Args:
      state: Current state containing build and test status information.

    Returns:
      Formatted string containing verification results, or empty string if
      no verification was performed.
    """
    status_parts = []

    if "run_build" in state and state["run_build"]:
      if "exist_build" in state and state["exist_build"]:
        status = "PASSED" if not state.get("build_fail_log") else "FAILED"
        status_parts.append(f"Build Status: {status}")

    if "run_test" in state and state["run_test"]:
      if "exist_test" in state and state["exist_test"]:
        status = "PASSED" if not state.get("test_fail_log") else "FAILED"
        status_parts.append(f"Test Status: {status}")

    if status_parts:
      return "Verification Results:\n" + "\n".join(status_parts)
    return ""

  def format_human_message(self, state: IssueAnswerAndFixState) -> HumanMessage:
    """Creates a formatted message combining all context for response generation.

    Formats the issue information, code changes, and verification status into
    a structured message for the language model.

    Args:
      state: Current state containing issue information, changes, and verification results.

    Returns:
      HumanMessage instance containing formatted context for response generation.
    """
    edit_status = "MODE: Information Only (No Code Changes)"

    # If this is a fix attempt (has patch)
    if "patch" in state and state["patch"]:
      edit_status = f"""\
MODE: Solution With Code Changes

CHANGES MADE:
{state["patch"]}

{self.format_verification_status(state)}
"""

    human_message = HumanMessage(
      self.HUMAN_PROMPT.format(
        title=state["issue_title"],
        body=state["issue_body"],
        comments=self.format_issue_comments(state.get("issue_comments", [])),
        summary=state["summary"],
        edit_status=edit_status,
      )
    )
    return human_message

  def __call__(self, state: IssueAnswerAndFixState):
    messages = [
      self.system_prompt,
      self.format_human_message(state),
    ]
    response = self.model.invoke(messages)
    self._logger.debug(f"IssueResponderNode reponse:\n{response}")
    return {"issue_response": response.content}
