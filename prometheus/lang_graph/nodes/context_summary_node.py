"""Context summarization for codebase-related queries and debugging.

This module implements a specialized assistant that organizes and summarize all the
KnowledgeGraph traversal context into a single summary.
"""

import logging
from typing import Sequence

from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage

from prometheus.lang_graph.subgraphs.context_provider_state import ContextProviderState


class ContextSummaryNode:
  """Organizes and presents comprehensive code context for debugging and understanding.

  This class processes and structures code-related context retrieved from knowledge
  graph searches, maintaining complete technical details while organizing information
  in relevance layers. It preserves all potentially relevant information including
  implementation details, configurations, and documentation.
  """

  SYS_PROMPT = """\
You are a technical context organizer. Present ALL relevant context while avoiding duplication:

CONTEXT PRESERVATION RULES:
1. For ALL files:
   - MUST include relative file path
   - Keep original text formatting
   - Maintain documentation as-is

2. For source code files:
   - Include start and end line numbers
   - Preserve complete implementations
   - Keep code formatting unchanged

3. Smart Deduplication:
   - If a class is included, omit its internal methods unless specifically relevant
   - Remove duplicate file content while keeping the most comprehensive version
   - Keep all unique implementations and documentation
  """

  HUMAN_PROMPT = """\
All retrieve context:
{all_context}
"""

  def __init__(self, model: BaseChatModel):
    """Initializes the ContextSummaryNode with a language model.

    Sets up the context summarizer with the necessary system prompts and
    logging configuration for processing retrieved context.

    Args:
      model: Language model instance that will be used for organizing and
        structuring context. Must be a BaseChatModel implementation
        suitable for detailed text processing and organization.
    """
    self.system_prompt = SystemMessage(self.SYS_PROMPT)
    self.model = model

    self._logger = logging.getLogger("prometheus.lang_graph.nodes.context_summary_node")

  def format_human_message(self, all_context_provider_responses: Sequence[BaseMessage]):
    """Creates a formatted message combining query and context.

    Combines the user query with formatted context messages into a single
    structured message for the language model.

    Args:
      query: User's original query string.
      context_messages: context_message generated by ContextProviderNode.

    Returns:
      HumanMessage instance containing the formatted query and context.
    """
    all_context = ""
    for response in all_context_provider_responses:
      all_context += f"{response.content}\n\n"
    return HumanMessage(self.HUMAN_PROMPT.format(all_context=all_context))

  def __call__(self, state: ContextProviderState):
    """Processes context state to generate organized summary.

    Takes the current context state, formats it into messages for the
    language model, and generates a comprehensive, well-structured
    summary of all relevant information.

    Args:
      state: Current state containing query and context messages.

    Returns:
      Dictionary that updates the state with the structured summary.
    """
    human_message = self.format_human_message(state["all_context_provider_responses"])
    message_history = [self.system_prompt, human_message]
    response = self.model.invoke(message_history)
    self._logger.debug(f"ContextSummaryNode response:\n{response}")
    return {"summary": response.content}
