import asyncio
from typing import (
    Union,
    cast,
)

from langchain_core.messages import (
    ToolCall,
    ToolMessage,
)
from langchain_core.runnables import RunnableConfig
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.errors import GraphInterrupt
from langgraph.graph import START, MessagesState, StateGraph
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.prebuilt.tool_node import (
    _handle_tool_error,
    _infer_handled_types,
    msg_content_output,
)

from prometheus.app.services.llm_service import get_model

# ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œå·¥å…·è°ƒç”¨
from prometheus.configuration.config import settings

# åˆ›å»ºè‡ªå®šä¹‰ ToolNode
preset_params = {
    "tavily-search": {
        "include_domains": ["pypi.org", "docs.python.org"],
        "exclude_domains": [
            "stackoverflow.com",
            "*huggingface*",
            "discourse.slicer.org",
            "ask.csdn.net",
            "codepudding.com",
            "*geeksforgeeks*",
            "*github*",
            "forum.developer.parrot.com",
        ],
    }
}


class CustomToolNode(ToolNode):
    """è‡ªå®šä¹‰ ToolNodeï¼Œæ”¯æŒä¸ºç‰¹å®šå·¥å…·æ·»åŠ é¢„è®¾å‚æ•°"""

    def __init__(self, tools, preset_params=None, **kwargs):
        super().__init__(tools, **kwargs)
        self.preset_params = preset_params or {}

    async def _arun_one(self, call: ToolCall, config: RunnableConfig) -> ToolMessage:
        if invalid_tool_message := self._validate_tool_call(call):
            return invalid_tool_message

        try:
            # æ„å»ºåŸºç¡€è¾“å…¥
            input = {**call, **{"type": "tool_call"}}

            # å¦‚æœè¿™ä¸ªå·¥å…·æœ‰é¢„è®¾å‚æ•°ï¼Œåˆ™æ·»åŠ åˆ°è¾“å…¥ä¸­
            if call["name"] in self.preset_params:
                preset_for_tool = self.preset_params[call["name"]]
                # é¢„è®¾å‚æ•°ä¼˜å…ˆçº§è¾ƒä½ï¼Œä¸ä¼šè¦†ç›–ç”¨æˆ·ä¼ é€’çš„å‚æ•°
                merged_args = {**preset_for_tool, **call.get("args", {})}
                input["args"] = merged_args
                print(f"ğŸ”§ ä¸ºå·¥å…· {call['name']} æ·»åŠ é¢„è®¾å‚æ•°: {preset_for_tool}")
                print(f"ğŸ”§ æœ€ç»ˆå‚æ•°: {merged_args}")

            tool_message: ToolMessage = await self.tools_by_name[call["name"]].ainvoke(
                input, config
            )
            tool_message.content = cast(Union[str, list], msg_content_output(tool_message.content))
            return tool_message
        except GraphInterrupt as e:
            raise e
        except Exception as e:
            # ä½¿ç”¨çˆ¶ç±»çš„é”™è¯¯å¤„ç†é€»è¾‘
            if isinstance(self.handle_tool_errors, tuple):
                handled_types: tuple = self.handle_tool_errors
            elif callable(self.handle_tool_errors):
                handled_types = _infer_handled_types(self.handle_tool_errors)
            else:
                handled_types = (Exception,)

            if not self.handle_tool_errors or not isinstance(e, handled_types):
                raise e
            else:
                content = _handle_tool_error(e, flag=self.handle_tool_errors)
                return ToolMessage(
                    content=content, name=call["name"], tool_call_id=call["id"], status="error"
                )


async def main():
    # è·å– Tavily API key
    tavily_api_key = settings.get("TAVILY_API_KEY", None)
    if tavily_api_key is None:
        print("é”™è¯¯: æœªè®¾ç½® TAVILY_API_KEY")
        return

    model = get_model(
        "gpt-4o-mini",
        openai_format_api_key=settings.get("OPENAI_FORMAT_API_KEY", None),
        openai_format_base_url=settings.get("OPENAI_FORMAT_BASE_URL", None),
        anthropic_api_key=None,
        gemini_api_key=None,
        temperature=0.0,
        max_output_tokens=15000,
    )

    async def init_tool():
        # ä½¿ç”¨ HTTP ä¼ è¾“ç›´æ¥è¿æ¥åˆ° Tavily MCP æœåŠ¡å™¨
        client = MultiServerMCPClient(
            {
                "tavily_web_search": {
                    "transport": "streamable_http",
                    "url": f"https://mcp.tavily.com/mcp/?tavilyApiKey={tavily_api_key}",
                }
            }
        )

        # å¼‚æ­¥è·å–å·¥å…·
        tools = await client.get_tools()
        print(f"è·å–åˆ°çš„å·¥å…·: {[tool.name for tool in tools]}")
        # for tool in tools:
        #     print(f"\nå·¥å…·åç§°: {tool.name}")
        #     if hasattr(tool, 'args_schema') and tool.args_schema:
        #         properties = tool.args_schema.get('properties', {})
        #         # ç®€å•çš„æ­£åˆ™åŒ¹é…è®¾ç½®é»˜è®¤å€¼
        #         for param_name in properties.keys():
        #             param_lower = param_name.lower()
        #             if re.search(r'include.*domain', param_lower):
        #                 properties[param_name]['default'] = ["pypi.org", "docs.python.org"]
        #                 print(f"  âœ… è®¾ç½® {param_name} é»˜è®¤å€¼: include domains")
        #             elif re.search(r'exclude.*domain', param_lower):
        #                 properties[param_name]['default'] = ["stackoverflow.com", "*huggingface", "discourse.slicer.org","ask.csdn.net",
        #                     "codepudding.com", "*geeksforgeeks*", "*github*", "forum.developer.parrot.com"]
        #                 print(f"  âœ… è®¾ç½® {param_name} é»˜è®¤å€¼: exclude domains")

        #             elif re.search(r'search.*depth', param_lower):
        #                 properties[param_name]['default'] = "advanced"
        #                 print(f"  âœ… è®¾ç½® {param_name} é»˜è®¤å€¼: advanced")
        return tools

    tools = await init_tool()

    async def call_model(state: MessagesState):
        messages = state["messages"]
        print("\n=== call_model è¢«è°ƒç”¨ ===")
        print(f"è¾“å…¥æ¶ˆæ¯æ•°é‡: {len(messages)}")

        print(f"å¯ç”¨å·¥å…·: {[tool.name for tool in tools]}")

        # ä½¿ç”¨çœŸå®æ¨¡å‹è°ƒç”¨ï¼Œç»‘å®šé¢„è®¾å‚æ•°çš„å·¥å…·
        model_with_tools = model.bind_tools(tools)
        print("å¼€å§‹è°ƒç”¨æ¨¡å‹...")

        response = await model_with_tools.ainvoke(messages)
        print(f"æ¨¡å‹å“åº”ç±»å‹: {type(response)}")

        return {"messages": [response]}

    # åˆ›å»ºå·¥å…·èŠ‚ç‚¹
    builder = StateGraph(MessagesState)
    builder.add_node("call_model", call_model)
    # builder.add_node("tools", CustomToolNode(tools, preset_params=preset_params))
    builder.add_node("tools", ToolNode(tools))

    # æ„å»ºå›¾
    builder.add_edge(START, "call_model")
    builder.add_conditional_edges(
        "call_model",
        tools_condition,
    )
    builder.add_edge("tools", "call_model")

    graph = builder.compile()

    # æ‰§è¡Œæµ‹è¯• - æ¼”ç¤ºå¦‚ä½•ä¼ é€’ include_domains ç­‰å‚æ•°
    # æ³¨æ„ï¼šå‚æ•°ä¼šåœ¨å·¥å…·è°ƒç”¨æ—¶ç”± LLM è‡ªåŠ¨ä¼ é€’ï¼Œè¿™é‡Œå±•ç¤ºä¸€ä¸ªéœ€è¦ç‰¹å®šåŸŸåæœç´¢çš„æŸ¥è¯¢
    test_query = """
    ERROR: Could not find a version that satisfies the requirement opencv (from versions: none)
    ERROR: No matching distribution found for opencv
    æŠ¥é”™
    """

    system_prompt = """\
    You are a web search assistant. When using the tavily_search tool, ALWAYS include these parameters:
    - exclude_domains: ["stackoverflow.com", "*huggingface*", "discourse.slicer.org","ask.csdn.net", "codepudding.com", "*geeksforgeeks*", "*github*", "forum.developer.parrot.com"]
    - include_domains: ['pypi.org', 'docs.python.org']
    - search_depth: "advanced"
    
    Make sure to explicitly pass these parameters in your tool call.
    """
    # system_prompt = """\
    # You are a web search assistant. help the human to find the answer to the question.
    # """

    response = await graph.ainvoke({"messages": system_prompt + "\n" + test_query})
    # print("Response:", response)

    return response


# è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
if __name__ == "__main__":
    result = asyncio.run(main())
    print(result["messages"][-1].content)
